{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: h5py in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (3.11.0)\n",
      "Requirement already satisfied: nilearn in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (0.10.4)\n",
      "Requirement already satisfied: transformers in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (4.39.3)\n",
      "Requirement already satisfied: torch in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (2.2.1+cu121)\n",
      "Requirement already satisfied: vit-pytorch in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (1.6.5)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from h5py) (1.26.2)\n",
      "Requirement already satisfied: joblib>=1.0.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from nilearn) (1.3.2)\n",
      "Requirement already satisfied: lxml in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from nilearn) (5.2.1)\n",
      "Requirement already satisfied: nibabel>=4.0.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from nilearn) (5.2.1)\n",
      "Requirement already satisfied: packaging in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from nilearn) (24.0)\n",
      "Requirement already satisfied: pandas>=1.1.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from nilearn) (2.1.4)\n",
      "Requirement already satisfied: requests>=2.25.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from nilearn) (2.31.0)\n",
      "Requirement already satisfied: scikit-learn>=1.0.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from nilearn) (1.3.2)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from nilearn) (1.11.4)\n",
      "Requirement already satisfied: filelock in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers) (3.13.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers) (0.22.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (4.10.0)\n",
      "Requirement already satisfied: sympy in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.4.127)\n",
      "Requirement already satisfied: einops>=0.7.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from vit-pytorch) (0.7.0)\n",
      "Requirement already satisfied: torchvision in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from vit-pytorch) (0.17.1+cu121)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pandas>=1.1.5->nilearn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pandas>=1.1.5->nilearn) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pandas>=1.1.5->nilearn) (2024.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests>=2.25.0->nilearn) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests>=2.25.0->nilearn) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests>=2.25.0->nilearn) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests>=2.25.0->nilearn) (2024.2.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from scikit-learn>=1.0.0->nilearn) (3.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torchvision->vit-pytorch) (10.3.0)\n",
      "Requirement already satisfied: six>=1.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas>=1.1.5->nilearn) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#Install prereqs, if necessary\n",
    "%pip install h5py nilearn transformers torch vit-pytorch torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Magic that doesn't work on lightning.ai for some reason\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enable access to dataset module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(\"/teamspace/studios/this_studio/mindscape/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the dataset & image pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading stimuli images...: 100%|██████████| 73000/73000 [01:27<00:00, 833.90it/s] \n"
     ]
    }
   ],
   "source": [
    "from ImageVoxelsDataset import ImageVoxelsDataset\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "\n",
    "#image pre-processing\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(), # convert np array from dataset to PIL\n",
    "    transforms.Resize((224, 224)), # resize to ViT dimensions\n",
    "    transforms.ToTensor() # convert back to tensor\n",
    "])\n",
    "\n",
    "#train for subject 1\n",
    "dataset = ImageVoxelsDataset('/teamspace/studios/this_studio/mindscape/nsd',\n",
    "                                subject=1, \n",
    "                                transform=transform, \n",
    "                                preload_imgs = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert betas back to percent signal change\n",
    "\n",
    "According to the [NSD Data Manual](https://cvnlab.slite.page/p/6CusMRYfk0/Untitled):\n",
    "\n",
    "\n",
    "> ...for some of [the] NSD data files that we have prepared, the betas have been multiplied by 300 and converted to int16 format to reduce space usage. Upon loading the beta files, the values should be immediately converted back to percent signal change by casting to decimal format (e.g. single or double) and dividing by 300.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_percent_signal_change(betas, idx):\n",
    "    return betas.float() / 300\n",
    "\n",
    "dataset.target_transform = to_percent_signal_change"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate STD and mean per session per voxel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:56<00:00,  1.40s/it]\n"
     ]
    }
   ],
   "source": [
    "from util import mean_sd_map\n",
    "from tqdm import tqdm\n",
    "\n",
    "session_size = 750\n",
    "\n",
    "#each entry is of the form mean, std_dev\n",
    "session_metrics = []\n",
    "\n",
    "for i in tqdm(range(0, len(dataset), session_size)):\n",
    "    session_set = torch.stack([dataset[i][1] for i in range(i, i+session_size)])\n",
    "    session_metrics.append(mean_sd_map(session_set))\n",
    "\n",
    "session_metrics = torch.stack(session_metrics, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([40, 2, 5246])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session_metrics.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize the betas\n",
    "\n",
    "Note: Mean and standard deviation before conversion of betas back to percent signal change are 1.762125820278688 and 3.0391348517898913, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This takes ~10 minutes to calculate. The values are provided below to save time\n",
    "# from util import find_mean_sd\n",
    "# MEAN, STD_DEV = find_mean_sd(dataset)\n",
    "# print(f\"mean: {MEAN}\\nstd. dev: {STD_DEV}\")\n",
    "# Before masking: MEAN, STD_DEV = 0.9780744683715907, 3.7325697644617897\n",
    "# MEAN, STD_DEV  = 1.762125820278688, 3.0391348517898913\n",
    "# def z_norm(n):\n",
    "#     return (n-MEAN) / STD_DEV\n",
    "\n",
    "# old_transform = dataset.target_transform\n",
    "# dataset.target_transform = lambda betas: z_norm(old_transform(betas))\n",
    "\n",
    "\n",
    "def norm(betas, idx):\n",
    "    sess = idx // 750\n",
    "    means, stds = session_metrics[sess]\n",
    "    \n",
    "    return (betas - means) / stds\n",
    "\n",
    "old_transform = dataset.target_transform\n",
    "dataset.target_transform = lambda betas, idx: norm(old_transform(betas, idx), idx)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matrixvit import MatrixViTModel\n",
    "from transformers import ViTConfig\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "dtype = torch.float32\n",
    "\n",
    "\n",
    "\n",
    "output_dims = dataset[0][1].shape\n",
    "num_voxels = np.prod(output_dims)\n",
    "hidden_size = (np.ceil(num_voxels/4) * 4).astype(np.int64) #round up to nearest multiple of 4 for flash attn compatiobility\n",
    "\n",
    "model = MatrixViTModel(\n",
    "    output_dimensions=output_dims,\n",
    "    image_size = (224, 224),\n",
    "    patch_size = (16, 16),\n",
    "    dim = hidden_size, #hidden size\n",
    "    depth = 6, #num hidden layers\n",
    "    heads = 8,\n",
    "    mlp_dim = 2*hidden_size, #intermediate size\n",
    "    drop_rate = 0.2  \n",
    ").to(device=device, dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "757293182"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter out duplicate images\n",
    "In practice these should really be averaged, but this is a proof of concept to see if this is what is confusing the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/30000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30000/30000 [01:07<00:00, 446.11it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "seen_images = set()\n",
    "\n",
    "unique_indices = []\n",
    "\n",
    "\n",
    "pbar = tqdm(dataset)\n",
    "\n",
    "for i, (image, _) in enumerate(pbar):\n",
    "    image = image.numpy().tobytes()\n",
    "    if image not in seen_images:\n",
    "        seen_images.add(image)\n",
    "        unique_indices.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import FilteredDataset\n",
    "\n",
    "dataset = FilteredDataset(dataset, unique_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/219 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 195/219 [05:04<00:37,  1.56s/it]"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, random_split\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from torch import nn, optim\n",
    "from util import set_seed\n",
    "from torchmetrics import R2Score\n",
    "import time\n",
    "\n",
    "#seed for reproducibility:\n",
    "set_seed(47)\n",
    "\n",
    "def seed_worker(worker_id):\n",
    "    set_seed(47 + worker_id)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "P_TRAIN = 0.7\n",
    "P_VAL = 0.1\n",
    "\n",
    "train_size = int(P_TRAIN * len(dataset))\n",
    "val_size = int(P_VAL * len(dataset))\n",
    "eval_size = len(dataset) - val_size - train_size\n",
    "\n",
    "train_dataset, val_dataset, eval_dataset = random_split(dataset, [train_size, val_size, eval_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset,  batch_size=32, num_workers=2, worker_init_fn=seed_worker)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, num_workers=1, worker_init_fn=seed_worker)\n",
    "\n",
    "\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5, factor=0.1, verbose=True, threshold=0.001)\n",
    "\n",
    "num_betas = dataset[0][1].shape[0]\n",
    "r2_score = R2Score(num_outputs = num_betas, multioutput=\"raw_values\").to(\"cuda\")\n",
    "\n",
    "num_epochs = 300\n",
    "\n",
    "\n",
    "model.to(\"cuda\")\n",
    "import time\n",
    "\n",
    "\n",
    "do_val = True\n",
    "\n",
    "try:\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Starting epoch {epoch+1}\")\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "\n",
    "        #Train\n",
    "        for images, targets in tqdm(train_loader):\n",
    "            images, targets = images.to('cuda'), targets.to('cuda')            \n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "\n",
    "            loss = loss_function(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        print(f'Epoch {epoch+1}, Training Loss: {avg_train_loss}')\n",
    "\n",
    "        if not do_val:\n",
    "            continue\n",
    "\n",
    "        #Validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        r2_score.reset()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, targets in val_loader:\n",
    "                \n",
    "                images, targets = images.to('cuda'), targets.to('cuda')\n",
    "                outputs = model(images)\n",
    "\n",
    "                loss = loss_function(outputs, targets)\n",
    "                val_loss += loss.item()\n",
    "                r2_score.update(outputs, targets)\n",
    "\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        val_r2 = r2_score.compute()  # Compute final R2 score for this epoch\n",
    "\n",
    "        print(f'Epoch {epoch+1}, Validation Loss: {avg_val_loss}, Median R^2 Score: {torch.median(val_r2)}, Mean R^2 Score: {torch.mean(val_r2)}')\n",
    "        scheduler.step(avg_val_loss)\n",
    "        #Save checkpoint\n",
    "        checkpoint = {\n",
    "            'epoch': epoch + 1,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'train_loss': avg_train_loss,\n",
    "            'val_loss': avg_val_loss,\n",
    "            'val_r2_score': val_r2  # Save the R2 score in the checkpoint\n",
    "\n",
    "        }\n",
    "        torch.save(checkpoint, f'checkpoint_epoch_{epoch+1}.pth')\n",
    "except KeyboardInterrupt:\n",
    "    train_loader = None"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
