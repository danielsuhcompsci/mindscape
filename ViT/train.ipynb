{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Install prereqs, if necessary\n",
    "%pip install h5py nilearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Magic that doesn't work on lightning.ai for some reason\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enable access to dataset module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "parent_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\n",
    "sys.path.append(parent_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the dataset & image pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ImageVoxelDataset import ImageVoxelsDataset\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "\n",
    "#image pre-processing\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(), # convert np array from dataset to PIL\n",
    "    transforms.Resize((224, 224)), # resize to ViT dimensions\n",
    "    transforms.ToTensor() # convert back to tensor\n",
    "])\n",
    "\n",
    "#train for subject 1\n",
    "dataset = ImageVoxelsDataset('./nsd', 1, transform=transform, cache_size = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert betas back to percent signal change\n",
    "\n",
    "According to the [NSD Data Manual](https://cvnlab.slite.page/p/6CusMRYfk0/Untitled):\n",
    "\n",
    "\n",
    "> ...for some of [the] NSD data files that we have prepared, the betas have been multiplied by 300 and converted to int16 format to reduce space usage. Upon loading the beta files, the values should be immediately converted back to percent signal change by casting to decimal format (e.g. single or double) and dividing by 300.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_percent_signal_change(betas):\n",
    "    return betas.float() / 300\n",
    "\n",
    "dataset.target_transform = to_percent_signal_change"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize the betas\n",
    "\n",
    "Note: Mean and standard deviation before conversion of betas back to percent signal change are 293.4223405114772 and 1119.770929338537, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This takes ~10 minutes to calculate. The values are provided below to save time\n",
    "# from util import find_mean_sd\n",
    "# MEAN, STD_DEV = find_mean_sd(dataset)\n",
    "MEAN, STD_DEV = 0.9780744683715907, 3.7325697644617897\n",
    "\n",
    "def z_norm(n):\n",
    "    return (n-MEAN) / STD_DEV\n",
    "\n",
    "old_transform = dataset.target_transform\n",
    "dataset.target_transform = lambda betas: z_norm(old_transform(betas))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matrixvit import MatrixViTModel\n",
    "\n",
    "output_dims = dataset[0][1].shape\n",
    "\n",
    "model = MatrixViTModel(\n",
    "    output_dimensions=output_dims\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, random_split\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "\n",
    "P_TRAIN = 0.8\n",
    "\n",
    "train_size = int(P_TRAIN * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "#not shuffling allows the cache to be effectively used\n",
    "train_loader = DataLoader(train_dataset, shuffle=False, batch_size=64, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, shuffle=False, batch_size=64, num_workers=4)\n",
    "\n",
    "\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 300\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "\n",
    "    #Train\n",
    "    for images, targets in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = loss_function(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "    print(f'Epoch {epoch+1}, Training Loss: {avg_train_loss}')\n",
    "\n",
    "    #Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, targets in val_loader:\n",
    "            outputs = model(images)\n",
    "            loss = loss_function(outputs, targets)\n",
    "            val_loss += loss.item()\n",
    "    \n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    print(f'Epoch {epoch+1}, Validation Loss: {avg_val_loss}')\n",
    "\n",
    "\n",
    "    #Save checkpoint\n",
    "    checkpoint = {\n",
    "        'epoch': epoch + 1,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "        'train_loss': avg_train_loss,\n",
    "        'val_loss': avg_val_loss\n",
    "    }\n",
    "    torch.save(checkpoint, f'checkpoint_epoch_{epoch+1}.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
