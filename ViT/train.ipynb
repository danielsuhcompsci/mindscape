{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: h5py in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (3.11.0)\n",
      "Requirement already satisfied: nilearn in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (0.10.4)\n",
      "Requirement already satisfied: transformers in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (4.39.3)\n",
      "Requirement already satisfied: torch in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (2.2.1+cu121)\n",
      "Requirement already satisfied: vit-pytorch in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (1.6.5)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from h5py) (1.26.2)\n",
      "Requirement already satisfied: joblib>=1.0.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from nilearn) (1.3.2)\n",
      "Requirement already satisfied: lxml in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from nilearn) (5.2.1)\n",
      "Requirement already satisfied: nibabel>=4.0.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from nilearn) (5.2.1)\n",
      "Requirement already satisfied: packaging in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from nilearn) (24.0)\n",
      "Requirement already satisfied: pandas>=1.1.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from nilearn) (2.1.4)\n",
      "Requirement already satisfied: requests>=2.25.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from nilearn) (2.31.0)\n",
      "Requirement already satisfied: scikit-learn>=1.0.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from nilearn) (1.3.2)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from nilearn) (1.11.4)\n",
      "Requirement already satisfied: filelock in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers) (3.13.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers) (0.22.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (4.10.0)\n",
      "Requirement already satisfied: sympy in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.4.127)\n",
      "Requirement already satisfied: einops>=0.7.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from vit-pytorch) (0.7.0)\n",
      "Requirement already satisfied: torchvision in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from vit-pytorch) (0.17.1+cu121)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pandas>=1.1.5->nilearn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pandas>=1.1.5->nilearn) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pandas>=1.1.5->nilearn) (2024.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests>=2.25.0->nilearn) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests>=2.25.0->nilearn) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests>=2.25.0->nilearn) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests>=2.25.0->nilearn) (2024.2.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from scikit-learn>=1.0.0->nilearn) (3.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torchvision->vit-pytorch) (10.3.0)\n",
      "Requirement already satisfied: six>=1.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas>=1.1.5->nilearn) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#Install prereqs, if necessary\n",
    "%pip install h5py nilearn transformers torch vit-pytorch torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Magic that doesn't work on lightning.ai for some reason\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enable access to dataset module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(\"/teamspace/studios/this_studio/mindscape/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the dataset & image pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading stimuli images...: 100%|██████████| 73000/73000 [00:22<00:00, 3264.42it/s]\n"
     ]
    }
   ],
   "source": [
    "from ImageVoxelsDataset import ImageVoxelsDataset\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "\n",
    "#image pre-processing\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(), # convert np array from dataset to PIL\n",
    "    transforms.Resize((224, 224)), # resize to ViT dimensions\n",
    "    transforms.ToTensor() # convert back to tensor\n",
    "])\n",
    "\n",
    "#train for subject 1\n",
    "dataset = ImageVoxelsDataset('/teamspace/studios/this_studio/mindscape/nsd',\n",
    "                                subject=1, \n",
    "                                transform=transform, \n",
    "                                preload_imgs = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert betas back to percent signal change\n",
    "\n",
    "According to the [NSD Data Manual](https://cvnlab.slite.page/p/6CusMRYfk0/Untitled):\n",
    "\n",
    "\n",
    "> ...for some of [the] NSD data files that we have prepared, the betas have been multiplied by 300 and converted to int16 format to reduce space usage. Upon loading the beta files, the values should be immediately converted back to percent signal change by casting to decimal format (e.g. single or double) and dividing by 300.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_percent_signal_change(betas):\n",
    "    return betas.float() / 300\n",
    "\n",
    "dataset.target_transform = to_percent_signal_change"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize the betas\n",
    "\n",
    "Note: Mean and standard deviation before conversion of betas back to percent signal change are 293.4223405114772 and 1119.770929338537, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This takes ~10 minutes to calculate. The values are provided below to save time\n",
    "# from util import find_mean_sd\n",
    "# MEAN, STD_DEV = find_mean_sd(dataset)\n",
    "# print(f\"mean: {MEAN}\\nstd. dev: {STD_DEV}\")\n",
    "MEAN, STD_DEV = 0.9780744683715907, 3.7325697644617897\n",
    "\n",
    "def z_norm(n):\n",
    "    return (n-MEAN) / STD_DEV\n",
    "\n",
    "old_transform = dataset.target_transform\n",
    "dataset.target_transform = lambda betas: z_norm(old_transform(betas))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matrixvit import MatrixViTModel\n",
    "from transformers import ViTConfig\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "dtype = torch.float32\n",
    "\n",
    "\n",
    "\n",
    "output_dims = dataset[0][1].shape\n",
    "\n",
    "model = MatrixViTModel(\n",
    "    output_dimensions=output_dims,\n",
    "    image_size = (224, 224),\n",
    "    patch_size = (16, 16),\n",
    "    dim = 768, #hidden size\n",
    "    depth = 6, #num hidden layers\n",
    "    heads = 8,\n",
    "    mlp_dim = 1024 #intermediate size    \n",
    ").to(device=device, dtype=dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/657 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 657/657 [00:50<00:00, 12.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training Loss: 5.337504886056735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Validation Loss: 0.4587599717556162, R^2 Score: -0.3577214777469635\n",
      "Starting epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 657/657 [00:50<00:00, 12.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Training Loss: 0.49092680646767173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Validation Loss: 0.4183196799552187, R^2 Score: -0.10443037748336792\n",
      "Starting epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 657/657 [00:51<00:00, 12.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Training Loss: 0.442193719213956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Validation Loss: 0.4197661109427188, R^2 Score: -0.10890914499759674\n",
      "Starting epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 657/657 [00:51<00:00, 12.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Training Loss: 0.4317242557146052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Validation Loss: 0.40348075171734427, R^2 Score: -0.05296771973371506\n",
      "Starting epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 657/657 [00:51<00:00, 12.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Training Loss: 0.42209928688030446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Validation Loss: 0.41671973783919153, R^2 Score: -0.07539434731006622\n",
      "Starting epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 657/657 [00:51<00:00, 12.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Training Loss: 0.4177285785272241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, random_split\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from torch import nn, optim\n",
    "from util import set_seed\n",
    "from torchmetrics import R2Score\n",
    "import time\n",
    "\n",
    "#seed for reproducibility:\n",
    "set_seed(47)\n",
    "\n",
    "def seed_worker(worker_id):\n",
    "    set_seed(47 + worker_id)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "P_TRAIN = 0.7\n",
    "P_VAL = 0.1\n",
    "\n",
    "train_size = int(P_TRAIN * len(dataset))\n",
    "val_size = int(P_VAL * len(dataset))\n",
    "eval_size = len(dataset) - val_size - train_size\n",
    "\n",
    "train_dataset, val_dataset, eval_dataset = random_split(dataset, [train_size, val_size, eval_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset,  batch_size=32, num_workers=2, worker_init_fn=seed_worker)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, num_workers=1, worker_init_fn=seed_worker)\n",
    "\n",
    "\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5, factor=0.1, verbose=True)\n",
    "\n",
    "num_betas = dataset[0][1].shape[0]\n",
    "r2_score = R2Score(num_outputs = num_betas, multioutput=\"uniform_average\").to(\"cuda\")\n",
    "\n",
    "num_epochs = 300\n",
    "\n",
    "\n",
    "model.to(\"cuda\")\n",
    "import time\n",
    "try:\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Starting epoch {epoch+1}\")\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "\n",
    "        #Train\n",
    "        for images, targets in tqdm(train_loader):\n",
    "            images, targets = images.to('cuda'), targets.to('cuda')            \n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "\n",
    "            loss = loss_function(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        print(f'Epoch {epoch+1}, Training Loss: {avg_train_loss}')\n",
    "\n",
    "        #Validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        r2_score.reset()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, targets in val_loader:\n",
    "                \n",
    "                images, targets = images.to('cuda'), targets.to('cuda')\n",
    "                outputs = model(images)\n",
    "\n",
    "                loss = loss_function(outputs, targets)\n",
    "                val_loss += loss.item()\n",
    "                r2_score.update(outputs, targets)\n",
    "\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        val_r2 = r2_score.compute()  # Compute final R2 score for this epoch\n",
    "\n",
    "        print(f'Epoch {epoch+1}, Validation Loss: {avg_val_loss}, R^2 Score: {val_r2}')\n",
    "\n",
    "        scheduler.step(avg_val_loss)\n",
    "\n",
    "        #Save checkpoint\n",
    "        checkpoint = {\n",
    "            'epoch': epoch + 1,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'train_loss': avg_train_loss,\n",
    "            'val_loss': avg_val_loss,\n",
    "            'val_r2_score': val_r2  # Save the R2 score in the checkpoint\n",
    "\n",
    "        }\n",
    "        torch.save(checkpoint, f'checkpoint_epoch_{epoch+1}.pth')\n",
    "except KeyboardInterrupt:\n",
    "    train_loader = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29009534"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "\n",
    "total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
